{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s54x-Gq4AiYb"
      },
      "source": [
        "## Simple Dendritic Gated Networks in numpy\n",
        "\n",
        "This colab implements a Dendritic Gated Network (DGN) solving a regression (using quadratic loss) or a binary classification problem (using Bernoulli log loss).\n",
        "\n",
        "See our paper titled [\"A rapid and efficient learning rule for biological neural circuits\"](https://www.biorxiv.org/content/10.1101/2021.03.10.434756v1) for details of the DGN model.\n",
        "\n",
        "\n",
        "Some implementation details:\n",
        "- We utilize `sklearn.datasets.load_breast_cancer` for binary classification and `sklearn.datasets.load_diabetes` for regression.\n",
        "- This code is meant for educational purposes only. It is not optimized for high-performance, both in terms of computational efficiency and quality of fit.\n",
        "- Network is trained on 80% of the dataset and tested on the rest. For classification, we report log loss (negative log likelihood) and accuracy (percentage of correctly identified labels). For regression, we report MSE expressed in units of target variance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jhiajfn0EAxE"
      },
      "outputs": [],
      "source": [
        "# Copyright 2021 DeepMind Technologies Limited. All rights reserved.\n",
        "#\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nm-F_uZA0_T2"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn import datasets\n",
        "from sklearn import preprocessing\n",
        "from sklearn import model_selection\n",
        "from typing import List, Optional"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LOoiBATk1AgQ"
      },
      "source": [
        "## Choose classification or regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FCjzwzwh0ycl"
      },
      "outputs": [],
      "source": [
        "do_classification = True  # if False, does regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TA5VmSeV-GTc"
      },
      "source": [
        "### Load dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qnzNZrzNk3Pl"
      },
      "outputs": [],
      "source": [
        "if do_classification:\n",
        "  features, targets = datasets.load_breast_cancer(return_X_y=True)\n",
        "else:\n",
        "  features, targets = datasets.load_diabetes(return_X_y=True)\n",
        "\n",
        "x_train, x_test, y_train, y_test = model_selection.train_test_split(\n",
        "    features, targets, test_size=0.2, random_state=0)\n",
        "n_features = x_train.shape[-1]\n",
        "\n",
        "# Input features are centered and scaled to unit variance:\n",
        "feature_encoder = preprocessing.StandardScaler()\n",
        "x_train = feature_encoder.fit_transform(x_train)\n",
        "x_test = feature_encoder.transform(x_test)\n",
        "\n",
        "if not do_classification:\n",
        "  # Continuous targets are centered and scaled to unit variance:\n",
        "  target_encoder = preprocessing.StandardScaler()\n",
        "  y_train = np.squeeze(target_encoder.fit_transform(y_train[:, np.newaxis]))\n",
        "  y_test = np.squeeze(target_encoder.transform(y_test[:, np.newaxis]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LTQxvDcok86S"
      },
      "source": [
        "## DGN inference/update"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F6Yt_tw0lmf1"
      },
      "outputs": [],
      "source": [
        "def step_square_loss(inputs: np.ndarray,\n",
        "                     weights: List[np.ndarray],\n",
        "                     hyperplanes: List[np.ndarray],\n",
        "                     hyperplane_bias_magnitude: Optional[float] = 1.,\n",
        "                     learning_rate: Optional[float] = 1e-5,\n",
        "                     target: Optional[float] = None,\n",
        "                     update: bool = False,\n",
        "                     ):\n",
        "  \"\"\"Implements a DGN inference/update using square loss.\"\"\"\n",
        "  r_in = inputs\n",
        "  side_info = np.hstack([hyperplane_bias_magnitude, inputs])\n",
        "\n",
        "  for w, h in zip(weights, hyperplanes):  # loop over layers\n",
        "    r_in = np.hstack([1., r_in])  # add biases\n",
        "    gate_values = np.heaviside(h.dot(side_info), 0).astype(bool)\n",
        "    effective_weights = gate_values.dot(w).sum(axis=1)\n",
        "    r_out = effective_weights.dot(r_in)\n",
        "\n",
        "    if update:\n",
        "      grad = (r_out[:, None] - target) * r_in[None]\n",
        "      w -= learning_rate * gate_values[:, :, None] * grad[:, None]\n",
        "\n",
        "    r_in = r_out\n",
        "  loss = (target - r_out)**2 / 2\n",
        "  return r_out, loss\n",
        "\n",
        "def sigmoid(x):  # numerically stable sigmoid\n",
        "  return np.exp(-np.logaddexp(0, -x))\n",
        "\n",
        "def inverse_sigmoid(x):\n",
        "  return np.log(x/(1-x))\n",
        "\n",
        "def step_bernoulli(inputs: np.ndarray,\n",
        "                   weights: List[np.ndarray],\n",
        "                   hyperplanes: List[np.ndarray],\n",
        "                   hyperplane_bias_magnitude: Optional[float] = 1.,\n",
        "                   learning_rate: Optional[float] = 1e-5,\n",
        "                   epsilon: float = 0.01,\n",
        "                   target: Optional[float] = None,\n",
        "                   update: bool = False,\n",
        "                   ):\n",
        "  \"\"\"Implements a DGN inference/update using Bernoulli log loss.\"\"\"\n",
        "  r_in = np.clip(sigmoid(inputs), epsilon, 1-epsilon)\n",
        "  side_info = np.hstack([hyperplane_bias_magnitude, inputs])\n",
        "\n",
        "  for w, h in zip(weights, hyperplanes):  # loop over layers\n",
        "    r_in = np.hstack([sigmoid(1.), r_in])  # add biases\n",
        "    h_in = inverse_sigmoid(r_in)\n",
        "    gate_values = np.heaviside(h.dot(side_info), 0).astype(bool)\n",
        "    effective_weights = gate_values.dot(w).sum(axis=1)\n",
        "    h_out = effective_weights.dot(h_in)\n",
        "    r_out_unclipped = sigmoid(h_out)\n",
        "    r_out = np.clip(r_out_unclipped, epsilon, 1 - epsilon)\n",
        "    if update:\n",
        "      update_indicator = np.abs(target - r_out_unclipped) \u003e epsilon\n",
        "      grad = (r_out[:, None] - target) * h_in[None]  * update_indicator[:, None]\n",
        "      w -= learning_rate * gate_values[:, :, None] * grad[:, None]\n",
        "    r_in = r_out\n",
        "  loss = - (target * np.log(r_out) + (1 - target) * np.log(1 - r_out))\n",
        "  return r_out, loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0B7wSn3Azcfb"
      },
      "outputs": [],
      "source": [
        "def forward_pass(step_fn, x, y, weights, hyperplanes, learning_rate, update):\n",
        "  losses, outputs = np.zeros(len(y)), np.zeros(len(y))\n",
        "  for i, (x_i, y_i) in enumerate(zip(x, y)):\n",
        "    outputs[i], losses[i] = step_fn(x_i, weights, hyperplanes, target=y_i,\n",
        "                                    learning_rate=learning_rate, update=update)\n",
        "  return np.mean(losses), outputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "41aHT8G0lsuu"
      },
      "source": [
        "## Define architecture\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WSbPuwzFvV2N"
      },
      "outputs": [],
      "source": [
        "# number of neurons per layer, the last element must be 1\n",
        "n_neurons = np.array([100, 10, 1])\n",
        "n_branches = 20  # number of dendritic brancher per neuron"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gTk1YDXV-xoD"
      },
      "source": [
        "## Initialise weights and gating parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uek-2I5IlyN3"
      },
      "outputs": [],
      "source": [
        "n_inputs = np.hstack([n_features + 1, n_neurons[:-1] + 1])  # 1 for the bias\n",
        "dgn_weights = [np.zeros((n_neuron, n_branches, n_input))\n",
        "               for n_neuron, n_input in zip(n_neurons, n_inputs)]\n",
        "\n",
        "# Fixing random seed for reproducibility:\n",
        "np.random.seed(12345)\n",
        "dgn_hyperplanes = [\n",
        "    np.random.normal(0, 1, size=(n_neuron, n_branches, n_features + 1))\n",
        "    for n_neuron in n_neurons]\n",
        "# By default, the weight parameters are drawn from a normalised Gaussian:\n",
        "dgn_hyperplanes = [\n",
        "    h_ / np.linalg.norm(h_[:, :, :-1], axis=(1, 2))[:, None, None]\n",
        "    for h_ in dgn_hyperplanes]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dy1XUdaSm0ID"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wublBSqiucQ-"
      },
      "outputs": [],
      "source": [
        "if do_classification:\n",
        "  eta = 1e-4\n",
        "  n_epochs = 3\n",
        "  step = step_bernoulli\n",
        "else:\n",
        "  eta = 1e-5\n",
        "  n_epochs = 10\n",
        "  step = step_square_loss\n",
        "\n",
        "if do_classification:\n",
        "  step = step_bernoulli\n",
        "else:\n",
        "  step = step_square_loss\n",
        "\n",
        "print('Training on {} problem for {} epochs with learning rate {}.'.format(\n",
        "    ['regression', 'classification'][do_classification], n_epochs, eta))\n",
        "print('This may take a minute. Please be patient...')\n",
        "\n",
        "for epoch in range(0, n_epochs + 1):\n",
        "  train_loss, train_pred = forward_pass(\n",
        "      step, x_train, y_train, dgn_weights,\n",
        "      dgn_hyperplanes, eta, update=(epoch \u003e 0))\n",
        "\n",
        "  test_loss, test_pred = forward_pass(\n",
        "      step, x_test, y_test, dgn_weights,\n",
        "      dgn_hyperplanes, eta, update=False)\n",
        "  to_print = 'epoch: {}, test loss: {:.3f} (train: {:.3f})'.format(\n",
        "      epoch, test_loss, train_loss)\n",
        "\n",
        "  if do_classification:\n",
        "    accuracy_train = np.mean(np.round(train_pred) == y_train)\n",
        "    accuracy = np.mean(np.round(test_pred) == y_test)\n",
        "    to_print += ', test accuracy: {:.3f} (train: {:.3f})'.format(\n",
        "        accuracy, accuracy_train)\n",
        "  print(to_print)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "last_runtime": {
        "build_target": "//learning/deepmind/dm_python:dm_notebook3",
        "kind": "private"
      },
      "name": "dendritic_gated_network.ipynb",
      "private_outputs": true,
      "provenance": [
        {
          "file_id": "1lzQUssVJpeziFs1fdBHueD7DqNp6lkVK",
          "timestamp": 1614705435731
        }
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
